<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>TempUN</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <style>
    .results-carousel .item {
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        height: 600px; /* Set a fixed height for all carousel items */
        background-color: white; /* White background for all items */
        margin-bottom: 40px;
    }
    .results-carousel .item img {
        max-width: 50%;
        max-height: 500px; /* Set a maximum height for images */
        width: auto;
        height: auto;
        object-fit: contain; /* Ensure the entire image is visible */
    }
</style>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">XME: Cross-lingual Editing in Multilingual Language Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://himanshubeniwal.github.io/" target="_blank">Himanshu Beniwal</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="https://in.linkedin.com/in/kowsik-nandagopan-d" target="_blank">Kowsik Nandagopan D</a><sup>*</sup>,</span>
                    <span class="author-block">
                  <span class="author-block">
                    <a href="https://mayank4490.github.io/" target="_blank">Mayank Singh</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Indian Institute of Technology Gandhinagar, India ðŸ‡®ðŸ‡³<br><b>EACL 2024 (Malta ðŸ‡²ðŸ‡¹)</b></span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://aclanthology.org/2024.findings-eacl.140/" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/lingo-iitgn/XME" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://drive.google.com/drive/folders/1BFthZvNEgCZ1Nt35nGCDYLwXVK7Y7as1?usp=sharing" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fa fa-database"></i>
                  </span>
                  <span>Data</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      
        <!-- Your video here -->
        <iframe src="https://drive.google.com/file/d/1pCkHC8KGg2vJWsYXN_JY00PhL6t_UhB-/preview" width="900px" height="500px" allow="autoplay"></iframe>
      
      <h3 class="subtitle has-text-centered">
        A short overview of the our work on the <b>Cross-lingual Model Editing (XME)</b>. 
      </h3>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The training of large language models (LLMs) necessitates substantial data and computational resources, and updating outdated LLMs entails significant efforts and resources. While numerous model editing techniques (METs) have emerged to efficiently update model outputs without retraining, their effectiveness in multilingual LLMs, where knowledge is stored in diverse languages, remains an underexplored research area. This research paper introduces the cross-lingual model editing (XME) paradigm, wherein a fact is edited in one language, and the subsequent update propagation is observed across other languages. To investigate the XME paradigm, we conducted experiments using BLOOM, mBERT, and XLM-RoBERTa using the two writing scripts: Latin (English, French, and Spanish) and Indic (Hindi, Gujarati, and Bengali). The results reveal notable performance limitations of state-of-the-art METs under the XME setting, mainly when the languages involved belong to two distinct script families. These findings highlight the need for further research and development of XME techniques to address these challenges. For more comprehensive information, the dataset used in this research and the associated code are publicly available at the following <a href="https://github.com/lingo-iitgn/XME"><b>[URL]</b></a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->
<br>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3" style="text-align: center;">What is "Cross-lingual Model Editing"?</h2>
      <img src="static/images/xme.png" alt="MY ALT TEXT"/>
        <!-- <h2 class="subtitle has-text-centered">
          First image description.
        </h2> -->
      <!-- <video poster="" id="tree" autoplay controls muted loop height="100%">
       Your video here -->
        <!-- <source src="static/images/problem.png"
        type="image"> -->
      <!-- </video> -->
      <h2 class="subtitle has-text-centered">
        Figure 1: XME pipeline: we update a fact in one language (say English) and check whether the same fact is updated in different languages.
      </h2>
    </div>
  </div>
</section>


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
      <div class="container">
        <h2 class="title is-3" style="text-align: center;">Contributions and Findings ðŸ’¡</h2>
          <div id="results-carousel" class="carousel results-carousel">
            
              <div class="item">
                  <img src="static/images/hypernetwork.png" alt="Categories and subcategories"/>
                  <h2 class="subtitle has-text-centered">
                    Figure 2: An outline for hypernetwork-based model editing technique.
                  </h2>
              </div>
              <div class="item">
                  <img src="static/images/dataset.png" alt="Second image"/>
                  <h2 class="subtitle has-text-centered">
                    Table 1: Dataset statistics in different languages. Note: TFR and VFR are the average length of training-filtered and validation-filtered rephrases, respectively. Inv<sub>bloom</sub> and Inv<sub>xlm</sub> are the inverse proportion of BLOOM and XLM-RoBERTa. Lastly, in all the languages, the size of validation and test remains 10444 and 1193, respectively.
                  </h2>
              </div>
              <div class="item">
                  <img src="static/images/GS.png" alt="Third image"/>
                  <h2 class="subtitle has-text-centered">
                    Table 2: The table represents G<sub>S</sub> for fine-tuned mBERT (left) and BLOOM (right) on â€˜enâ€™ dataset using MEND.
                  </h2>
              </div>
              <div class="item">
                  <img src="static/images/SS.png" alt="Fourth image"/>
                  <h2 class="subtitle has-text-centered">
                    Table 3: The table represents S<sub>S</sub> for fine-tuned mBERT on the â€˜enâ€™ (left) and â€˜hiâ€™ (right) dataset using MEND.
                  </h2>
              </div>
              <div class="item">
                <img src="static/images/FT_Lan.png" alt="Fifth image"/>
                <h2 class="subtitle has-text-centered">
                  Figure 3: The figure illustrates G<sub>S</sub> given the editing language (x-axis) and fine-tuning languages (y-axis) for all the three models BLOOM (left), mBERT (middle) and XLM-RoBERTa (right) when edited using MEND.
                </h2>
            </div>
            <div class="item">
              <img src="static/images/mix_inv.png" alt="Sixth image"/>
              <h2 class="subtitle has-text-centered">
                Figure 4: The figure illustrates G<sub>S</sub> (Left) and G<sub>S</sub> (Right) given the editing language (x-axis) and fine-tuning datasets (y-axis) for all the three models BLOOM (top), mBERT (middle) and XLM-RoBERTa (right) when edited using MEND.
              </h2>
          </div>
          </div>
      </div>
  </div>
</section>



<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
     
      <h2 class="title is-3" style="text-align: center;">Detailed Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            
            <iframe src="https://www.youtube.com/embed/g38gQ8ykUSw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3" style="text-align: center;">Poster</h2>

      <iframe  src="static/pdfs/poster.pdf" width="100%" height="700">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{beniwal-etal-2024-cross,
        title = "Cross-lingual Editing in Multilingual Language Models",
        author = "Beniwal, Himanshu  and
          D, Kowsik  and
          Singh, Mayank",
        editor = "Graham, Yvette  and
          Purver, Matthew",
        booktitle = "Findings of the Association for Computational Linguistics: EACL 2024",
        month = mar,
        year = "2024",
        address = "St. Julian{'}s, Malta",
        publisher = "Association for Computational Linguistics",
        url = "https://aclanthology.org/2024.findings-eacl.140",
        pages = "2078--2128",
        abstract = "The training of large language models (LLMs) necessitates substantial data and computational resources, and updating outdated LLMs entails significant efforts and resources. While numerous model editing techniques (METs) have emerged to efficiently update model outputs without retraining, their effectiveness in multilingual LLMs, where knowledge is stored in diverse languages, remains an underexplored research area. This research paper introduces the cross-lingual model editing (XME) paradigm, wherein a fact is edited in one language, and the subsequent update propagation is observed across other languages. To investigate the XME paradigm, we conducted experiments using BLOOM, mBERT, and XLM-RoBERTa using the two writing scripts: Latin (English, French, and Spanish) and Indic (Hindi, Gujarati, and Bengali). The results reveal notable performance limitations of state-of-the-art METs under the XME setting, mainly when the languages involved belong to two distinct script families. These findings highlight the need for further research and development of XME techniques to address these challenges. For more comprehensive information, the dataset used in this research and the associated code are publicly available at the following [URL](https://github.com/lingo-iitgn/XME).",
    }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
